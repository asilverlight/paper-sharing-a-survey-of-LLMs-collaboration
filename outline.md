# abstract
探究了LLM的合作策略

合并（merge）：在参数空间中整合多个llm

集成（ensemble）：结合不同的llm的输出

协作（cooperation）：利用不同llm在多种任务中发挥多样化的能力
# introduction
先描述了人类合作的成果——集体合作的能力远超过个人所能达到的水平
目前🤗上有大量的llm可供使用，专攻不同

challenge：没有一个单一的模型在所有任务上始终优于其他model，于是人们开始探究llm之间的合作，以发掘model的潜能

前两种merge和ensemble方法是基于传统的机器学习中的融合技术来的。
本文的survey集中于利用llm的不同优势来实现特定任务目标的合作方法
# background
##  Collaboration for LLMs
合作策略通常用于提高模型对特定任务的性能
不同llm有差异的原因：
- 训练语料库and模型架构差异
- 针对特定领域的微调
llm之间的合作策略可能有助于解决模型计算效率低下、幻觉和隐私泄露等问题
模型合作主要包括如下方面：
- 合并（merge）：将多个LLMs整合成一个统一的、更强大的模型
  - 合并模型参数来接近相对最优解的策略
  - 增强多任务处理能力
- 集成（ensemble）：结合不同的llm的输出
  - 集成策略
  - 集成应用
- 协作（cooperation）：利用不同llm在多种任务中发挥多样化的能力
  - 高效计算
  - 知识迁移
  - 使用额外的控制器来补偿LLMs的不足
  - 联邦学习和联邦提示
# merging
单一模型具有固有的局限性，比如可能遗漏重要信息（Sagi和Rokach，2018），并且容易陷入局部最优或缺乏多任务能力。为了解决这些限制，研究人员已经探索了模型合并方法，这种方法在参数空间中结合多个模型以创建一个统一的、更强的模型。

（当前的merge方法仅适用于具有相同架构和参数的同一空间内模型，∴候选的合并模型应该用相同的初始化来训练）
## M-ROS
原理：现代深度神经网络的局部最优解是通过简单曲线连接的，沿着这些曲线可以在不同的局部最优解之间移动，而不会对模型的训练或测试精度产生太大影响，这为模型融合提供了可能性

M-ROS的基本方法就是使用参数平均，通过平均各种局部最优解整合了不同模型的优势，减少了个别模型的偏差和方差
### 基本M-ROS方法：
简单参数平均：对于k个候选模型，M = {M1,M2, · · · ,Mk}，
$$\theta^* = \frac{1}{k} \sum_{i=1}^{k} \theta_{M_i}$$
针对模型的选择，uniform soup方法简单地对所有model取平均；greedy soup每次向候选池中添加一个model，确保新model在验证集上性能有所提高或保持不变；DiWA方法根据候选模型在验证集上的表现对其进行排名，并且只有当新模型能提升性能时才会添加

加权平均：根据单个模型的重要性或质量为其分配不同的系数
$$\theta^* = \sum_{i=1}^{k} \alpha_i \cdot \theta_{M_i}$$
learned soup在验证集上优化混合系数以最小化损失函数

使用fisher信息矩阵来衡量模型参数的重要性，并使用重要性分数作为合并系数

基于几何关系的方法，根据参数之间角度差值来微调模型
### 提高合并后llm性能
模型在特定任务上微调后，其参数的变化可以用来确定在合并过程中各个模型应占的权重

利用在预训练过程中保存的LLM检查点，并结合贝叶斯优化来在广阔的搜索空间中导航，以识别最优的合并系数

## M-MTC
motivation：一些具有不同能力的model是由同一个model经过finetune而来，导致其参数空间出现分歧。M-MTC方法旨在减轻这种分歧，并实现对具有不同能力的模型的平衡合并，从而产生一个能够处理多个任务的单一模型

### 加权平均
与M-ROS中加权平均类似
### 基于任务属性的方法
基于加权平均的合并方法强调了参数的重要性，但忽略了它们的任务特定属性，导致在某些任务中性能显著下降

最新的研究定义了一个任务向量$\tau_t$，该向量表示参数空间中的一个方向，使得沿着该方向的移动可以提高任务上的性能

$$\tau_t = \theta^{ft}_t - \theta^{pre}$$

参数冲突：两个或更多模型参数更新方向相反或互相矛盾

干扰原因：跨模型的冗余参数值和符号不一致性

解决参数冲突：
进行算术运算、考虑不同模型参数重要性、采用进化算法优化合并模型内数据推理路径、ZIPIT（识别高度相关的参数，并在合并时保留显著不同的层，从而在合并过程中保持模型的多样性）

参数剪枝：通过丢弃和重新缩放参数减少冗余、选择重要的参数进行融合、动态修剪分区放大

### 增量训练
在模型参数空间内找到一个共享低维子空间，以最小化任务干扰而不会显著影响性能

引入了一种表示手术技术，以减轻多任务模型融合中的表示偏差
# ensemble
集成学习专注于模型输出的组合
## 集成方法
### 推理前集成
目的：为特定的example选择最合适的llm，通过训练外部router来选择model

zooter系统：使用奖励模型，利用训练集计算query-output对的分数，之后使用知识蒸馏训练router，使其能够仅根据输入的query来选择最佳llm

- 利用奖励模型评估不同model对同一query的响应质量，从而确定哪个模型在特定任务上表现更好

根据预测的查询难度和所需质量级别将query分配给小model

通过收集三元组（query，output，score）来训练router
### 推理中集成
motivation：model在推理过程中，以自回归的方式生成token，但这一过程常常导致幻觉的积累

解决方法：将llm与一些效果较好的、比较小的lm结合，通过加权平均的方式重新调整输出分布；对输出分布进行插值，以提高翻译任务的性能；使用frugal fusion of experts方法，将其视为图的最短路径问题来提出一种有效的融合方法

上述集成方法要求：llm具有相同词汇表，从而确保输出分布能够对齐

当llm是异质的，具有不同词汇表：

使用动态规划的方法，计算两个序列的匹配分数，并根据该匹配分数递归地最小化计算成本；将重叠的token作为锚点，并将异构的llm的输出分布投影到同一空间内（学习不同词汇表之间的映射关系or计算从锚点到不同词汇表的相对表示，以实现间接投影）
### 推理后集成
构建llm级联：
将models的输出按照各自model本身参数数量排序，一旦前面较小的llm生成了足够质量的output，就停止并返回目前的输出；首先验证由较小的llm生成答案的准确性，如果初始答案不准确，则利用llm解决问题

从众多输出中选择最佳输出：
在构造指令数据集时，可以根据产生的多个candidates的质量选择最佳的instruction
### 关于集成效果的讨论
- 推理速度：
  几乎所有的集成方法都会降低推理速度。ensemble before inference使用了router；ensemble during inference在计算过程中，要求每个llm都参与推理，之后综合llms的结果，因此如果我们有k个LLMs，推理速度将降低k倍；ensemble after inference不仅需要k倍计算成本，还要额外时间选择融合输出，因此推理速度最慢
- 细粒度：
  before和after的时候集成是粗粒度的，而during的时候处理的是token，是细粒度的。由于先前的token经常影响后续的token，这种细粒度的集成可以减少曝光偏差（Ranzato等人，2015；Xu等人，2020）并减少大型语言模型中的幻觉，因此具有更好的性能提升潜力
- 局限性：
  - before方法需要额外训练router
  - during方法不同llm架构不同，导致model之间输出分布无法对应，从而阻碍直接集成
  - candidates和selection strategy是主要限制因素
## 应用
llm集成可以在特定领域发挥重要作用，同时可以在RLHF中缓解过度优化问题，提高对齐性能
# cooperation
## 高效计算
较小的lm可以加速运算
### 输入压缩
使用小lm压缩输入prompts或长文本内容，以缩短输入长度和需要处理的token数量，提高内存效率

输入压缩主要集中于对prompt进行剪枝（删除输入prompt中不重要的token、句子或文档），将prompt压缩为更短的摘要，soft prompt压缩

- prompt剪枝
  
  除去不重要的token、句子或文档
- prompt摘要提取
  
  训练摘要提取模型or删除部分token

  通过原始query和一个document生成摘要

  对句子分组，每组生成一个摘要

- soft prompt压缩
  
  使用llm为输入prompt的特殊位置插入某些虚拟标记，之后模型会输出一组虚拟标记，接着将刚才插入虚拟标记的prompt和新输出的一组虚拟标记相结合，产生一个更短的prompt
### 推测解码
推测性解码：小lm生成drafts，然后llm验证drafts以加速推理

drafts是一系列tokens，代表了对输入问题的初步理解和响应

大模型采用诸如贪婪解码or核采样等方法，逐步接受小模型产生的drafts
## 知识迁移
### 纠正错误知识
对比解码（CD）：通过对比大模型和能力较弱的业余模型的输出分布来选择token $y_i$
$$y_i \sim log P_{LLM}(y_i|y<i) - log P_{AMA}(y_i|y<i)$$
该方法非常重要，为后续一系列方法奠定了基础

注意llms和业余模型通常属于同一族的模型，需要对齐输出分布
### 增强正确知识
通过llm的合作增强output对input的置信度。使用额外的模型来加强正确的知识，增加可能正确输出的可能性

该方法基于贝叶斯分布，通过verifier模型预测input和output的关系：
$$p(c | y_i, y_{<i})$$
c是model输入

整体方法如下：
$$p(y_i | y_{<i}, c) \propto p(y_i | y_{<i}) \cdot p(c | y_i, y_{<i})$$
$$y_i \sim log P_{LLM}(y_i|y_{<i}) + log P_{VER}(c|y_i,y_{<i})$$
### 加入新知识
修改大模型输出的logit，并将从小模型中提取出的新能力输入到大模型中

提前需要训练小模型以使其获得新能力
$$\log p_{\mathrm{LARGE-C}}(y_i|y_{<i}) \propto \log p_{\mathrm{LARGE}}(y_i|y_{<i}) + [\log p_{\mathrm{SMALL-C}}(y_i|y_{<i}) - \log p_{\mathrm{SMALL}}(y_i|y_{<i})]$$
要求小模型和大模型拥有相同的词汇表
## 互补合作
引入额外的控制器来弥补llm的不足
### detector
llm可能会因为缺乏相关知识而产生错误的回应或幻觉。因此，检测LLMs中的幻觉对于确保生成内容的可靠性和可信度至关重要
- 事实幻觉
  生成内容可能会与现实世界存在差异

  主要通过模型生成内容与外部知识源进行比较

  RARR：使用自然语言推理评估句子与事实的一致性
  factcheck：识别证据的立场并收集相关证据，然后它使用RARR来确定收集的证据是否支持原始文本
  programfc：将复杂的声明分解成若干子任务
  salam利用辅助模型帮助llm通过交互式合作模型从错误中学习
  使用信息检索模型检索相关段落，之后使用摘要模型压缩检索内容并验证llm输出
- 忠实度幻觉
  生成内容与input之间可能会存在偏差

  基于分类器的方法：使用分类器评估生成的句子是否与证据文档中内容相一致

  基于问答驱动的方法：将输入指令转换为若干query，之后使用QA系统找到答案，并将找到的答案与生成的文本相比较，检查一致性，以确定生成的文本是否忠实于原始指令或上下文
### retriever
针对RAG系统而言，引入retriever的生成模型（根据检索内容生成）也算作是一种模型协作
## 联邦合作
问题：公共领域数据稀缺，私有数据隐私需要保护

解决方法：联邦学习
### 联邦训练
服务器上的llm知识可以转移到客户端小模型上，而客户端小模型独特的知识可以丰富llm的分布

为了弥合llm和slm的差距，使用fedmkt框架，来参数高效地做联合知识转移

使用OpenFedLLM的框架，多个数据所有者可以在不传输原始数据的情况下合作训练一个共享模型
### 联邦提示工程
使用本地小模型保护用户隐私，云端大模型执行用户指令

本地小模型将用户的prompt转化为通用的prompt，然后由大模型输入prompt，将结果返回到本地设备

由于联邦学习会花费过多训练时间收敛，并且最终的模型不一定准确，因此引入promptfl方法，引入了提示学习器，其更新提示而不是更新整个模型
# challenge and future work
## 需要更灵活的合并方法
当前的大型语言模型合并方法通常仅限于具有相同架构和兼容参数的模型。然而，大多数开源的大型语言模型是异构的，使得当前的合并方法无效
## 针对ensemble来说，平衡速度和性能
## 通过合作实现更广泛的应用
探索跨领域应用，大型语言模型可以结合它们在各个领域的专业知识，将开启新的可能性。此外，以人为本的合作也是一个有前景的方向